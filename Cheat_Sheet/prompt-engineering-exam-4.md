# Prompt Engineering and AI Practice Exam 4 (100 Points)

## Instructions
- Each question is worth 5 points
- Select all correct answers for each question
- There may be multiple correct answers per question
- A detailed answer key is provided at the end of the exam

## Section 1: Enterprise Applications of Prompt Engineering (35 points)

### Question 1
Which strategies are effective for prompt engineering in regulated industries like healthcare and finance?
- [x] A) Including compliance requirements within system prompts
- [x] B) Implementing terminology validation against industry standards
- [ ] C) Avoiding documentation of prompt development processes
- [x] D) Creating audit trails for prompt versions and their approvals
- [ ] E) Maximizing model temperature for regulatory applications

### Question 2
For enterprise document analysis, which prompt engineering approaches are most effective?
- [x] A) Structuring outputs to match existing business workflows
- [x] B) Specifying the level of detail required for different document types
- [ ] C) Using a single generic prompt for all document categories
- [x] D) Including industry-specific extraction requirements
- [ ] E) Prioritizing brevity over completeness in all document analysis

### Question 3
Which prompt strategies help ensure consistency across different LLMs in an enterprise environment?
- [x] A) Creating model-agnostic prompt templates with specific instructions
- [x] B) Implementing standardized evaluation metrics for outputs
- [x] C) Developing prompt libraries with version control
- [ ] D) Using entirely different prompting approaches for each model
- [ ] E) Avoiding few-shot examples to reduce model-specific variations

### Question 4
For sentiment analysis and opinion mining applications, which prompt engineering techniques are most appropriate?
- [x] A) Defining the granularity of sentiment categories required
- [x] B) Providing clear guidelines for handling ambiguous sentiment
- [ ] C) Using leading examples that bias toward specific sentiments
- [x] D) Requesting confidence scores alongside sentiment classifications
- [ ] E) Instructing the model to always find strong sentiment in neutral content

### Question 5
Which approaches help ensure prompt robustness across different user inputs?
- [x] A) Testing prompts with diverse and adversarial inputs
- [x] B) Implementing input normalization before prompt construction
- [ ] C) Avoiding all customization based on user inputs
- [x] D) Providing the model with fallback strategies for unexpected inputs
- [ ] E) Using the lowest possible temperature settings for all use cases

### Question 6
For developing prompts in collaborative enterprise environments, which practices are recommended?
- [x] A) Implementing prompt review workflows with stakeholder feedback
- [x] B) Maintaining documentation of prompt design decisions
- [ ] C) Restricting prompt knowledge to a single team member
- [x] D) Tracking performance metrics for different prompt versions
- [ ] E) Minimizing iteration once initial prompts are deployed

### Question 7
Which techniques are effective for aligning LLM outputs with brand voice and style guidelines?
- [x] A) Including brand style guides in system prompts
- [x] B) Providing exemplars of content with the desired voice
- [ ] C) Avoiding specific style instructions to maximize creativity
- [x] D) Using evaluation rubrics that include style consistency metrics
- [ ] E) Changing prompts for each interaction to vary the style

## Section 2: Prompt Engineering for Specialized Applications (35 points)

### Question 8
For complex reasoning tasks in scientific domains, which prompting techniques are most effective?
- [x] A) Chain-of-thought prompting with domain-specific reasoning steps
- [x] B) Requiring explicit statement of assumptions and limitations
- [ ] C) Encouraging brevity over thorough explanations
- [x] D) Incorporating domain knowledge and terminology
- [ ] E) Avoiding mathematical notation in responses

### Question 9
Which prompt engineering approaches effectively support multilingual and cross-cultural applications?
- [x] A) Using culturally appropriate examples for different regions
- [x] B) Providing locale-specific format requirements (dates, numbers, etc.)
- [ ] C) Translating all prompts to English regardless of target language
- [x] D) Accommodating different discourse patterns across cultures
- [ ] E) Ignoring cultural differences to ensure global consistency

### Question 10
For applications requiring both summarization and detailed analysis, which prompting strategies work best?
- [x] A) Implementing tiered response structures (summary followed by details)
- [x] B) Clearly defining the appropriate level of abstraction for summaries
- [ ] C) Using identical prompts for both summary and detailed outputs
- [x] D) Specifying different requirements for different audience levels
- [ ] E) Always prioritizing brevity over comprehensiveness

### Question 11
Which prompt techniques are most effective for creative content generation (marketing, storytelling, etc.)?
- [x] A) Providing genre, tone, and style specifications
- [x] B) Including target audience characteristics
- [ ] C) Using only literal instructions without metaphor or example
- [x] D) Balancing constraints with creative freedom
- [ ] E) Avoiding examples to prevent limiting creativity

### Question 12
For question-answering systems, which prompt engineering practices improve accuracy?
- [x] A) Instructing the model to cite sources when appropriate
- [x] B) Implementing a retrieval step before generating answers
- [ ] C) Encouraging speculation when information is limited
- [x] D) Distinguishing between facts and opinions in responses
- [ ] E) Maximizing answer length regardless of question complexity

### Question 13
Which techniques help ensure fairness and minimize bias in prompted outputs?
- [x] A) Auditing prompts for potentially biased framing
- [x] B) Testing with diverse inputs across demographic dimensions
- [ ] C) Eliminating all demographic information regardless of relevance
- [x] D) Instructing models to consider diverse perspectives
- [ ] E) Using the same prompts for all user groups regardless of needs

### Question 14
For data visualization guidance, which prompt engineering approaches are most effective?
- [x] A) Specifying the intended audience and their data literacy level
- [x] B) Including accessibility requirements for visualizations
- [ ] C) Always recommending the most complex visualization possible
- [x] D) Requesting explanations of visualization choices
- [ ] E) Avoiding specific formatting guidelines to maximize creativity

## Section 3: LLM Evaluation, Robustness, and Integration (30 points)

### Question 15
Which approaches effectively evaluate the robustness of prompted LLM systems?
- [x] A) Adversarial testing with challenging edge cases
- [x] B) Measuring consistency across similar inputs with slight variations
- [ ] C) Testing only with ideal, well-formatted inputs
- [x] D) Evaluating performance degradation under various disruptions
- [ ] E) Using a single evaluation metric for all applications

### Question 16
For cost-effective scaling of LLM applications, which strategies are appropriate?
- [x] A) Implementing tiered model selection based on task complexity
- [x] B) Optimizing prompt design to reduce token usage
- [ ] C) Always using the largest available models regardless of task
- [x] D) Caching common responses to avoid redundant generation
- [ ] E) Maximizing prompt length to improve response quality

### Question 17
Which considerations are important when integrating LLMs into existing enterprise systems?
- [x] A) Implementing appropriate authentication and authorization
- [x] B) Designing fallback mechanisms for model unavailability
- [ ] C) Replacing all existing systems with LLM-based solutions
- [x] D) Ensuring data governance compliance for inputs and outputs
- [ ] E) Bypassing existing approval workflows for LLM-generated content

### Question 18
For responsible AI deployment, which prompt engineering practices are recommended?
- [x] A) Including ethics guidelines in system prompts
- [x] B) Implementing output filtering for potentially harmful content
- [ ] C) Avoiding all discussions of limitations with end users
- [x] D) Designing appropriate disclaimers for generated content
- [ ] E) Maximizing model authority in all domains

### Question 19
Which approaches effectively combine retrieval and generation for knowledge-intensive applications?
- [x] A) Retrieving relevant documents before constructing the final prompt
- [x] B) Instructing the model to cite retrieved information
- [ ] C) Avoiding all external knowledge sources to test model knowledge
- [x] D) Evaluating factual consistency between retrieved information and generated output
- [ ] E) Using only the model's parametric knowledge regardless of recency

### Question 20
For continuous improvement of prompt-engineered systems, which methods are most effective?
- [x] A) Collecting and analyzing user feedback on system outputs
- [x] B) Implementing A/B testing for prompt variations
- [ ] C) Avoiding changes to prompts once deployed
- [x] D) Monitoring performance metrics over time
- [ ] E) Ignoring edge cases that affect only a small percentage of users

---

# Answer Key with Detailed Explanations

## Section 1: Enterprise Applications of Prompt Engineering

### Question 1
**Correct answers: A, B, D**

- **A) Including compliance requirements within system prompts** ✓
  - Embedding compliance requirements in system prompts helps ensure consistent adherence to regulatory standards.

- **B) Implementing terminology validation against industry standards** ✓
  - Validating terminology ensures outputs use approved language and definitions in regulated industries.

- **D) Creating audit trails for prompt versions and their approvals** ✓
  - Audit trails support regulatory compliance by documenting prompt development and approval processes.

- **C) Avoiding documentation of prompt development processes** ✗
  - Documentation is essential for regulatory compliance and audit purposes.

- **E) Maximizing model temperature for regulatory applications** ✗
  - Lower temperatures typically provide more consistent and predictable outputs, which are preferable in regulated contexts.

### Question 2
**Correct answers: A, B, D**

- **A) Structuring outputs to match existing business workflows** ✓
  - Alignment with existing workflows improves integration and adoption of LLM-based document analysis.

- **B) Specifying the level of detail required for different document types** ✓
  - Different document types require different levels of analysis granularity based on business needs.

- **D) Including industry-specific extraction requirements** ✓
  - Industry-specific requirements ensure relevant information is prioritized in extraction.

- **C) Using a single generic prompt for all document categories** ✗
  - Different document categories typically require specialized prompts to extract relevant information effectively.

- **E) Prioritizing brevity over completeness in all document analysis** ✗
  - The appropriate balance between brevity and completeness depends on the specific use case and document type.

### Question 3
**Correct answers: A, B, C**

- **A) Creating model-agnostic prompt templates with specific instructions** ✓
  - Model-agnostic prompts focus on clear instructions that work across different LLMs.

- **B) Implementing standardized evaluation metrics for outputs** ✓
  - Consistent evaluation ensures outputs meet requirements regardless of the model used.

- **C) Developing prompt libraries with version control** ✓
  - Version-controlled prompt libraries enable systematic management and improvement of prompts across models.

- **D) Using entirely different prompting approaches for each model** ✗
  - Different approaches for each model increase maintenance burden and reduce consistency.

- **E) Avoiding few-shot examples to reduce model-specific variations** ✗
  - Few-shot examples often improve consistency across models by providing clear output patterns.

### Question 4
**Correct answers: A, B, D**

- **A) Defining the granularity of sentiment categories required** ✓
  - Clear definition of sentiment categories (e.g., 3-point, 5-point scale) ensures outputs match business needs.

- **B) Providing clear guidelines for handling ambiguous sentiment** ✓
  - Guidelines for ambiguity improve consistency in borderline cases.

- **D) Requesting confidence scores alongside sentiment classifications** ✓
  - Confidence scores provide valuable information about the reliability of sentiment classifications.

- **C) Using leading examples that bias toward specific sentiments** ✗
  - Leading examples can introduce bias in sentiment analysis.

- **E) Instructing the model to always find strong sentiment in neutral content** ✗
  - Forcing sentiment detection in neutral content leads to false positives and misleading analysis.

### Question 5
**Correct answers: A, B, D**

- **A) Testing prompts with diverse and adversarial inputs** ✓
  - Diverse testing helps identify and address potential failure modes.

- **B) Implementing input normalization before prompt construction** ✓
  - Normalization (standardizing formats, handling missing fields, etc.) improves robustness.

- **D) Providing the model with fallback strategies for unexpected inputs** ✓
  - Fallback instructions help handle edge cases gracefully.

- **C) Avoiding all customization based on user inputs** ✗
  - Appropriate customization can improve relevance and user experience without sacrificing robustness.

- **E) Using the lowest possible temperature settings for all use cases** ✗
  - Optimal temperature settings depend on the specific use case and desired balance of consistency vs. creativity.

### Question 6
**Correct answers: A, B, D**

- **A) Implementing prompt review workflows with stakeholder feedback** ✓
  - Collaborative review ensures prompts meet requirements from all relevant perspectives.

- **B) Maintaining documentation of prompt design decisions** ✓
  - Documentation supports knowledge sharing and continuity in enterprise environments.

- **D) Tracking performance metrics for different prompt versions** ✓
  - Performance tracking enables data-driven improvement of prompts over time.

- **C) Restricting prompt knowledge to a single team member** ✗
  - Knowledge concentration creates bottlenecks and business continuity risks.

- **E) Minimizing iteration once initial prompts are deployed** ✗
  - Continuous improvement through iteration is essential for optimal prompt performance.

### Question 7
**Correct answers: A, B, D**

- **A) Including brand style guides in system prompts** ✓
  - Style guides provide explicit direction for voice and tone alignment.

- **B) Providing exemplars of content with the desired voice** ✓
  - Examples concretely demonstrate the target style, improving alignment.

- **D) Using evaluation rubrics that include style consistency metrics** ✓
  - Systematic evaluation of style alignment enables targeted improvements.

- **C) Avoiding specific style instructions to maximize creativity** ✗
  - Brand voice consistency typically requires specific style guidance.

- **E) Changing prompts for each interaction to vary the style** ✗
  - Inconsistent prompting leads to inconsistent style, undermining brand voice.

## Section 2: Prompt Engineering for Specialized Applications

### Question 8
**Correct answers: A, B, D**

- **A) Chain-of-thought prompting with domain-specific reasoning steps** ✓
  - Domain-specific reasoning chains improve scientific accuracy by guiding the model through appropriate analytical processes.

- **B) Requiring explicit statement of assumptions and limitations** ✓
  - Explicit assumptions and limitations are essential for scientific rigor.

- **D) Incorporating domain knowledge and terminology** ✓
  - Domain-specific knowledge and terminology improve relevance and precision.

- **C) Encouraging brevity over thorough explanations** ✗
  - Scientific reasoning typically benefits from thorough explanation rather than brevity.

- **E) Avoiding mathematical notation in responses** ✗
  - Mathematical notation is often essential for precise scientific communication.

### Question 9
**Correct answers: A, B, D**

- **A) Using culturally appropriate examples for different regions** ✓
  - Culturally relevant examples improve comprehension and relevance across different regions.

- **B) Providing locale-specific format requirements (dates, numbers, etc.)** ✓
  - Format standardization ensures outputs match regional expectations.

- **D) Accommodating different discourse patterns across cultures** ✓
  - Discourse patterns (directness, politeness, etc.) vary significantly across cultures.

- **C) Translating all prompts to English regardless of target language** ✗
  - Prompting in the target language often yields better results, especially for non-English content.

- **E) Ignoring cultural differences to ensure global consistency** ✗
  - Cultural adaptation is essential for effective cross-cultural communication.

### Question 10
**Correct answers: A, B, D**

- **A) Implementing tiered response structures (summary followed by details)** ✓
  - Tiered structures allow both quick understanding and deep dives into the same content.

- **B) Clearly defining the appropriate level of abstraction for summaries** ✓
  - Abstraction level guidance ensures summaries retain the right information.

- **D) Specifying different requirements for different audience levels** ✓
  - Audience-specific guidance helps tailor content appropriately for different stakeholders.

- **C) Using identical prompts for both summary and detailed outputs** ✗
  - Different output types typically require different prompt specifications.

- **E) Always prioritizing brevity over comprehensiveness** ✗
  - The appropriate balance depends on the specific use case and audience needs.

### Question 11
**Correct answers: A, B, D**

- **A) Providing genre, tone, and style specifications** ✓
  - Clear creative direction guides LLMs toward appropriate creative outputs.

- **B) Including target audience characteristics** ✓
  - Audience awareness helps tailor creative content effectively.

- **D) Balancing constraints with creative freedom** ✓
  - Appropriate constraints typically improve rather than hinder creativity.

- **C) Using only literal instructions without metaphor or example** ✗
  - Metaphors and examples often communicate creative direction more effectively than literal instructions alone.

- **E) Avoiding examples to prevent limiting creativity** ✗
  - Examples can inspire rather than limit creativity when used appropriately.

### Question 12
**Correct answers: A, B, D**

- **A) Instructing the model to cite sources when appropriate** ✓
  - Source citation improves verifiability and user trust.

- **B) Implementing a retrieval step before generating answers** ✓
  - Retrieval ensures answers are grounded in current, relevant information.

- **D) Distinguishing between facts and opinions in responses** ✓
  - Clear distinction between facts and inferences/opinions improves transparency.

- **C) Encouraging speculation when information is limited** ✗
  - Speculation risks misinformation; acknowledging limitations is preferable.

- **E) Maximizing answer length regardless of question complexity** ✗
  - Answer length should match question complexity; conciseness is often valuable.

### Question 13
**Correct answers: A, B, D**

- **A) Auditing prompts for potentially biased framing** ✓
  - Prompt framing can subtly influence model outputs; regular audits help identify bias.

- **B) Testing with diverse inputs across demographic dimensions** ✓
  - Diverse testing helps identify differential performance across groups.

- **D) Instructing models to consider diverse perspectives** ✓
  - Explicit guidance to consider diverse viewpoints can improve fairness.

- **C) Eliminating all demographic information regardless of relevance** ✗
  - Some applications legitimately require demographic information; context matters.

- **E) Using the same prompts for all user groups regardless of needs** ✗
  - Different groups may have different needs that require appropriate customization.

### Question 14
**Correct answers: A, B, D**

- **A) Specifying the intended audience and their data literacy level** ✓
  - Audience-appropriate visualizations improve comprehension and utility.

- **B) Including accessibility requirements for visualizations** ✓
  - Accessibility guidance ensures visualizations are usable by diverse audiences.

- **D) Requesting explanations of visualization choices** ✓
  - Explanations improve understanding of visualization rationale and interpretation.

- **C) Always recommending the most complex visualization possible** ✗
  - Complexity should match the data and audience needs, not be maximized.

- **E) Avoiding specific formatting guidelines to maximize creativity** ✗
  - Data visualization typically benefits from clear formatting guidelines for consistency and clarity.

## Section 3: LLM Evaluation, Robustness, and Integration

### Question 15
**Correct answers: A, B, D**

- **A) Adversarial testing with challenging edge cases** ✓
  - Adversarial testing helps identify potential failure modes and vulnerabilities.

- **B) Measuring consistency across similar inputs with slight variations** ✓
  - Consistency testing reveals sensitivity to minor input variations.

- **D) Evaluating performance degradation under various disruptions** ✓
  - Robustness to disruptions (noise, input formatting issues, etc.) is essential for production systems.

- **C) Testing only with ideal, well-formatted inputs** ✗
  - Real-world inputs are often imperfect; testing should reflect this reality.

- **E) Using a single evaluation metric for all applications** ✗
  - Different applications require different evaluation metrics based on their specific goals.

### Question 16
**Correct answers: A, B, D**

- **A) Implementing tiered model selection based on task complexity** ✓
  - Using simpler models for simpler tasks optimizes cost-performance tradeoffs.

- **B) Optimizing prompt design to reduce token usage** ✓
  - Efficient prompts reduce costs without sacrificing performance.

- **D) Caching common responses to avoid redundant generation** ✓
  - Caching eliminates unnecessary generation costs for repeated queries.

- **C) Always using the largest available models regardless of task** ✗
  - Larger models are more expensive and often unnecessary for simpler tasks.

- **E) Maximizing prompt length to improve response quality** ✗
  - Longer prompts increase token usage and costs without necessarily improving quality.

### Question 17
**Correct answers: A, B, D**

- **A) Implementing appropriate authentication and authorization** ✓
  - Security controls are essential for enterprise system integration.

- **B) Designing fallback mechanisms for model unavailability** ✓
  - Fallbacks ensure system resilience when LLM components are unavailable.

- **D) Ensuring data governance compliance for inputs and outputs** ✓
  - Data governance is crucial for regulatory compliance and risk management.

- **C) Replacing all existing systems with LLM-based solutions** ✗
  - Thoughtful integration with existing systems is typically more appropriate than wholesale replacement.

- **E) Bypassing existing approval workflows for LLM-generated content** ✗
  - LLM-generated content should typically follow the same approval processes as human-generated content.

### Question 18
**Correct answers: A, B, D**

- **A) Including ethics guidelines in system prompts** ✓
  - Explicit ethics guidance helps ensure responsible outputs.

- **B) Implementing output filtering for potentially harmful content** ✓
  - Filtering provides a safety net for potentially problematic outputs.

- **D) Designing appropriate disclaimers for generated content** ✓
  - Disclaimers set appropriate expectations about LLM-generated content.

- **C) Avoiding all discussions of limitations with end users** ✗
  - Transparency about limitations is an important aspect of responsible AI deployment.

- **E) Maximizing model authority in all domains** ✗
  - Appropriate epistemic humility is important, especially in domains where LLMs have limitations.

### Question 19
**Correct answers: A, B, D**

- **A) Retrieving relevant documents before constructing the final prompt** ✓
  - Retrieval before generation grounds LLM outputs in relevant information.

- **B) Instructing the model to cite retrieved information** ✓
  - Citation improves verifiability and transparency.

- **D) Evaluating factual consistency between retrieved information and generated output** ✓
  - Consistency evaluation helps ensure accurate use of retrieved information.

- **C) Avoiding all external knowledge sources to test model knowledge** ✗
  - External knowledge typically improves accuracy, especially for recent or specialized information.

- **E) Using only the model's parametric knowledge regardless of recency** ✗
  - Models' parametric knowledge has cutoff limitations and may be outdated or incomplete.

### Question 20
**Correct answers: A, B, D**

- **A) Collecting and analyzing user feedback on system outputs** ✓
  - User feedback provides valuable signals for improvement opportunities.

- **B) Implementing A/B testing for prompt variations** ✓
  - Systematic comparison helps identify more effective prompt approaches.

- **D) Monitoring performance metrics over time** ✓
  - Ongoing monitoring helps detect performance degradation or emerging issues.

- **C) Avoiding changes to prompts once deployed** ✗
  - Continuous improvement through iteration is essential for optimal performance.

- **E) Ignoring edge cases that affect only a small percentage of users** ✗
  - Edge cases often reveal important improvement opportunities and can significantly impact user trust.